{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2: Linear Models\n",
        "---\n",
        "\n",
        "## Exercise 1. Linear Classification\n",
        "For this exercise, you will need several packages. Let's import them using the following code.\n",
        "\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    import numpy as np\n",
        "                    from sklearn import datasets\n",
        "                    from sklearn import decomposition\n",
        "                    from sklearn.model_selection import train_test_split\n",
        "                    from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "Now, please complete the following steps. \n",
        "\n",
        "- Load the [diabetes dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) and convert its labels from numerical to categorical using the average of all labels: if `values` `<` `average`, set label `= 1` else set label `= -1`.\n"
      ],
      "metadata": {
        "id": "PhmhjSMz0vNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Perform the 6:2:2 split of the dataset (training set, validation set, test set). Store the training set in `X_train` and `y_train`. Tip: you may find `train_test_split` ([link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) useful. "
      ],
      "metadata": {
        "id": "ZFrKTk2d0dQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Train a linear classifier on the dataset using the built-in functions provided by `sklearn` as follows.\n",
        "\n",
        "\n",
        "                    from sklearn.linear_model import SGDClassifier\n",
        "                    clf = SGDClassifier(random_state=42)\n",
        "                    clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "- The coefficients $\\theta$ and intercept $\\theta_0$ can be accessed as `clf.coef_` and `clf.intercept_`, respectively. Please check the dimensions of `clf.coef_` and `clf.intercept_`.\n"
      ],
      "metadata": {
        "id": "MVjc_L1CzZNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Next, let's implement two utility functions below. You may want to take a look at matrix-multiplications using numpy ([link](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html)).\n",
        "\n",
        "                    def compute_prediction(X, coef, intercept):\n",
        "                      # Returns predictions as a 1-D array\n",
        "                      ##### YOUR CODE HERE #####\n",
        "                      return result\n",
        "\n",
        "                    def compute_accuracy(pred, actual):\n",
        "                      # Returns the prediction accuracy in percentage\n",
        "                        ##### YOUR CODE HERE #####\n",
        "                        return accuracy"
      ],
      "metadata": {
        "id": "x8VEclxO0P_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `compute_prediction` that you just wrote to obtain predictions on the training set, validation set, and test set. Check the shapes of the predictions.\n",
        "\n",
        "                    # Compute predictions manually\n",
        "                    pred_train = compute_prediction(X_train, coef, intercept)\n",
        "                    pred_val = compute_prediction(X_val, coef, intercept)\n",
        "                    pred_test = compute_prediction(X_test, coef, intercept)\n",
        "\n",
        "                    print(pred_train.shape, pred_val.shape, pred_test.shape)\n",
        "                    \n",
        "\n"
      ],
      "metadata": {
        "id": "vJ3k8TWk3PNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `compute_accuracy` that you just wrote to obtain accuracies on the predictions made on the training set, validation set, and test set, respectively. \n",
        "\n",
        "                    # Accuracies on predictions\n",
        "                    acc_train = compute_accuracy(pred_train,y_train)\n",
        "                    acc_val = compute_accuracy(pred_val,y_val)\n",
        "                    acc_test = compute_accuracy(pred_test,y_test)\n",
        "\n",
        "                    print(f\"Accuracies from the functions we wrote:\\n {acc_train}, {acc_val}, {acc_test}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "z5HSm03FzenM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For the training set, validation set, and test set, use the built-in functions `clf.predict()` and `clf.score()` of the classifier to make predictions and obtain accuracies. Are the results the same?\n",
        "\n",
        "                    # Scores (accuracy be default) on the predictions\n",
        "                    acc_train_clf = clf.score(X_train,y_train)\n",
        "                    acc_val_clf = clf.score(X_val,y_val)\n",
        "                    acc_test_clf = clf.score(X_test,y_test)\n",
        "\n",
        "                    print(f\"Accuracies from the built in function:\\n {acc_train_clf}, {acc_val_clf}, {acc_test_clf}\")"
      ],
      "metadata": {
        "id": "WM8Clv9g36wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise 2. Linear Regression\n",
        "For this exercise, we are going to write a gradient-based method to solve a linear regression task. \n",
        "\n",
        "\n",
        "First, let's import the packages. \n",
        "\n",
        "                    from sklearn.datasets import make_regression\n",
        "                    import matplotlib.pyplot as plt\n",
        "\n",
        "Next, use the following code to generate and inspect the data.\n",
        "\n",
        "                    X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "                    fig, ax = plt.subplots(figsize = (10,6), dpi = 80)\n",
        "                    ax.set_xlabel('X')\n",
        "                    ax.set_ylabel('y')\n",
        "                    ax.scatter(X,y,label=\"training data\")\n",
        "                    ax.legend()\n"
      ],
      "metadata": {
        "id": "itDdvabI3QGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now, please implement the following two functions. The pseudocode is shown below.\n",
        "\n",
        "![pseudo](https://user-images.githubusercontent.com/96804013/152409472-fe7a981f-eec9-471e-b684-bc028dd4c872.png)\n",
        "\n",
        "\n",
        "                    def gradient_descent(X, y, init_slope, init_intercept, learning_rate, num_iter)\n",
        "                      # The main gradient descent function\n",
        "                      ##### YOUR CODE HERE ####\n",
        "                      return new_slope, new_intercept\n",
        "\n",
        "                    def gradient_one_step(X, y, slope, intercept, learning_rate):\n",
        "                      # Function for taking one gradient step\n",
        "                      ##### YOUR CODE HERE ####\n",
        "                      return slope, intercept\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7B6rzAZ_7rRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Set other parameters for the learning algorithm as follows.\n",
        "\n",
        "                    learning_rate = 0.01 # Learning rate\n",
        "                    init_slope = 0 # Initial slope\n",
        "                    init_intercept = 0 # Initial intercept\n",
        "                    num_iter = 1000 # Number of iterations\n",
        "\n",
        "Finally, using the produced slope and intercept, you can plot the fitted line, i.e., the trained/learnt linear model, using the following code. \n",
        "\n",
        "                    slope, intercept = gradient_descent(X, y, init_slope, init_intercept, learning_rate, num_iter)\n",
        "\n",
        "                    ### Plot the generated data again\n",
        "                    fig, ax = plt.subplots(figsize=(10,6), dpi = 80)\n",
        "                    ax.scatter(X,y,label=\"training data\")\n",
        "                    ax.set_xlabel('X')\n",
        "                    ax.set_ylabel('y')\n",
        "\n",
        "                    ### Plot the model learned to see how well it fit the data\n",
        "                    ax.plot(X, slope*X + intercept, color=\"red\", label=\"fitted line\")\n",
        "                    ax.legend()\n",
        "\n"
      ],
      "metadata": {
        "id": "XnSFptdl7zAY"
      }
    }
  ]
}