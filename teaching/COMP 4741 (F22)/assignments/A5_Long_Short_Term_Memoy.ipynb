{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: Long-Short Term Memory\n",
        "---\n",
        "\n",
        "In this assignment, we will use Long-Short Term Memory (LSTM) ([link](https://en.wikipedia.org/wiki/Long_short-term_memory)) to predict the number of passengers in an airline for the next day given the number of passengers today. The data is represented as a time series.\n",
        "\n",
        "First, let's import necessary libraries.\n",
        "\n",
        "                    \n",
        "                    import math\n",
        "                    import numpy as np\n",
        "                    import pandas as pd\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    from sklearn.preprocessing import MinMaxScaler\n",
        "                    from sklearn.metrics import mean_squared_error\n",
        "                    from sklearn.model_selection import train_test_split\n",
        "\n",
        "                    from tensorflow import keras\n",
        "                    from keras.models import Sequential\n",
        "                    from keras.layers import Dense, LSTM\n"
      ],
      "metadata": {
        "id": "QhKxron-RIHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code for downloading the data and visualizing a subset of it is provided below.\n",
        "\n",
        "                    airlines = pd.read_csv('https://github.com/weizi-li/weizi-li.github.io/blob/master/teaching/airline-passengers.csv')\n",
        "                    print(f\"Dataset\\n{airlines.head()}\\n\")\n",
        "\n",
        "                    subset_size = 40 \n",
        "                    subset_months= airlines['Month'][0:subset_size]\n",
        "                    subset_passengers = airlines['Passengers'][0:subset_size]\n",
        "\n",
        "                    fig, ax = plt.subplots(figsize=(14,4), dpi = 80)\n",
        "                    ax.plot(range(len(subset_months)), np.array(subset_passengers), '+', label = \"Passenger count\")\n",
        "                    ax.plot(range(len(subset_months)), np.array(subset_passengers), alpha = 0.5)\n",
        "                    ax.set_xticks(range(len(subset_months))) \n",
        "                    ax.set_xticklabels(subset_months); # ';' prevents displaying auxillary outputs\n",
        "                    plt.xticks(rotation=45);\n",
        "                    ax.legend()\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153318289-1be2e715-5180-48f7-bdb1-9f41b9952b4c.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 1:Visualization of raw dataset</em>\n",
        "</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CwBELpiXc6WI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only be working with the Passengers column. Let's use the code below to process the data.\n",
        "\n",
        "- extract the Passengers column \n",
        "- take a look at it \n",
        "- convert its type \n",
        "- rehsape it \n",
        "- print its shape and the minimum and maximum values \n",
        "\n",
        "                    passengers = airlines['Passengers']\n",
        "                    print(f\"Passengers column\\n{passengers.head()}\")\n",
        "\n",
        "                    dataset = passengers.values.astype('float32').reshape(-1,1)\n",
        "                    print(f\"\\nBefore Normalization :\\n shape ={dataset.shape}, max = {np.max(dataset)}, min = {np.min(dataset)}\")"
      ],
      "metadata": {
        "id": "l8N_cY04wiIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's normalize the data, i.e., the `dataset` variable, using Minmax Scaler ([link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)). \n",
        "  - Instantiate a MinMaxScaler() object and make the feature range between 0 and 1\n",
        "  - Use the `fit_transform` function of MinMaxScaler to scale the dataset\n",
        "  - Print the shape of dataset and the minimum and maximum values after normalization \n",
        "  \n",
        "The shape `(144,1)` indicates the data has the format `[[data 0], [data 1], [data 2].... [data 143]]`.\n",
        "\n",
        "Now use the following code to reshape the dataset to `(144,)`. \n",
        "Now we have made the data look like this `[data 0, data 1, data2,.... data 143]`.\n",
        "\n",
        "                    dataset = dataset.reshape(-1)\n",
        "                    print(dataset.shape)"
      ],
      "metadata": {
        "id": "0sWUI9Gan9xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction problem is formulated in such a way that we want to look at the passenger number of Day 0 (today) to predict the pessenger number of Day 1 (tomorrow), i.e., there exists an 1 day difference between input feature and output label (`look back = 1`). The below figure demonstrates how we convert a single sequence of data into labelled examples.  \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153277436-42e975b8-043a-4d8a-8752-eea10d93767e.png\")\n",
        "\"/>\n",
        "\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 2: Conversion of Sequential data to (x,y) format (Figure Drawn for look back = 1).</em>\n",
        "</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "Now, use the following code to prepare the training set.  \n",
        "\n",
        "                    def gen_dataset(dset, look_back):\n",
        "                      X = []\n",
        "                      y = []\n",
        "                      for i in range(len(dset)-look_back-1):\n",
        "                        y_value = dset[i + look_back] # output label\n",
        "                        x_value = dset[i : i + look_back] # input feature\n",
        "                        y.append(y_value)\n",
        "                        X.append(x_value)\n",
        "                      \n",
        "                      return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "k1TB_TPg3Dcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can make use of the function we just wrote as follows.\n",
        "\n",
        "                    look_back = 1\n",
        "                    data_X, data_y = gen_dataset(dataset, look_back)\n",
        "                    print(data_X.shape, data_y.shape)"
      ],
      "metadata": {
        "id": "9siTq8b7EkK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's prepare for learning:\n",
        "\n",
        "- Split the dataset (data_X, data_y) into training set and test set with 7:3 ratio.\n",
        "- Set `shuffle` to `True` and `random_state` to `42` for repeatable experiments.\n",
        "- Store the values in `X_train`, `X_test`, `y_train`, and `y_test`\n",
        "- Check the shapes of `X_train`, `X_test`, `y_train`, and `y_test`\n",
        "- Reference ([link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))"
      ],
      "metadata": {
        "id": "J_U_sIKoB2Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, build an LSTM model with two layers: \n",
        "\n",
        "- 1st layer: LSTM layer with 100 units; specify `input_shape = (1, look_back)`\n",
        "- 2nd layer: dense layer with one unit\n",
        "\n",
        "\n",
        "Now compile and train the model:\n",
        "\n",
        "- for compiling, set `loss` to `mean_squared_error` and `optimizer` to `adam`\n",
        "- for training, set `epochs` to 10, `batch_size` to 1, and `verbose` to 2\n",
        "\n",
        "\n",
        "References\n",
        "- LSTM ([link](https://keras.io/api/layers/recurrent_layers/lstm/))\n",
        "- Dense ([link](https://keras.io/api/layers/core_layers/dense/))\n",
        "- Compile and fit ([link](https://keras.io/api/models/model_training_apis/))\n"
      ],
      "metadata": {
        "id": "1RF3jrYFYYGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the model is trained. Let's test it to see the error (RMSE). We have to reverse the normalization procedure for the predictions. To do so, we use the same scaler that is instantiated and `fitted` earlier.\n",
        "\n",
        "    \n",
        "                    pred_train = lstm.predict(X_train)\n",
        "                    pred_test = lstm.predict(X_test)\n",
        "\n",
        "                    pred_train = scaler.inverse_transform(pred_train)\n",
        "                    pred_test = scaler.inverse_transform(pred_test)\n",
        "\n",
        "                    y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "                    y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "              \n",
        "                    train_rmse = math.sqrt(mean_squared_error(y_train, pred_train))\n",
        "                    test_rmse = math.sqrt(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "                    print(f\"Train RMSE = {train_rmse} \\nTest RMSE = {test_rmse}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uiBkM70BpGQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's compare some predictions against the actual labels. \n",
        "        \n",
        "                    def plot(predictions, ground_truths, type = '', plot_x_size = 30):\n",
        "                      predictions = predictions.reshape(-1)[0:plot_x_size]\n",
        "                      ground_truths = ground_truths.reshape(-1)[0: plot_x_size]\n",
        "                      x_axis = range(plot_x_size)\n",
        "\n",
        "                      fig, ax = plt.subplots(figsize=(12,4), dpi = 80)\n",
        "                      ax.plot(x_axis, predictions, alpha = 0.5) \n",
        "                      ax.plot(x_axis, predictions, 'o',label = \"predictions\") \n",
        "                      ax.plot(x_axis, ground_truths, alpha = 0.5) \n",
        "                      ax.plot(x_axis, ground_truths, 'x', label = \"ground truths\") \n",
        "\n",
        "                      ax.set_xticks(x_axis);\n",
        "                      ax.set_xlabel(\"Day number\")\n",
        "                      ax.set_ylabel(\"Passenger Count\")\n",
        "                      ax.set_title(f\"Model performance on a subset of {type} set\")\n",
        "                      ax.legend()\n",
        "                      plt.show()\n",
        "\n",
        "                    plot(pred_train, y_train, 'train')\n",
        "                    plot(pred_test, y_test, 'test')\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153318480-c85d408d-41e0-4470-a815-ed1467e9b0dd.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 3:Visualization of LSTM predictions on train and test</em>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "nsMZxnSl0eyL"
      }
    }
  ]
}