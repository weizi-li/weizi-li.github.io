{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhYAk_ydd86A"
      },
      "source": [
        "# Assignment 6: Autoencoder and Variational Autoencoder\n",
        "---\n",
        "\n",
        "In this assignment, we will train an autoencoder that can denoise images in the CIFAR10 dataset ([link](https://en.wikipedia.org/wiki/CIFAR-10)).\n",
        "\n",
        "In addition, we will train a variational autoencoder that can learn a distribution of low-dimensional representation of the MNIST dataset ([link](https://en.wikipedia.org/wiki/MNIST_database)). The distribution can be later used to generate fake images.  \n",
        "\n",
        "---\n",
        "## Exercise 1-1. Autoencoder\n",
        "\n",
        "Let's start by importing the necessary packages.\n",
        "\n",
        "                    import random\n",
        "                    import numpy as np\n",
        "                    import matplotlib.pyplot as plt\n",
        "\n",
        "                    import tensorflow as tf \n",
        "                    from tensorflow import keras \n",
        "                    from keras.datasets import mnist, cifar10\n",
        "                    from keras.models import Sequential\n",
        "\n",
        "                    from keras import Model\n",
        "                    from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dense, Flatten, Reshape, Input\n",
        "\n",
        "\n",
        "Next, let's set some seeds for experiment reproducibility.\n",
        "\n",
        "                    SEED = 99\n",
        "                    random.seed(SEED)\n",
        "                    np.random.seed(SEED)\n",
        "                    tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's do the following.\n",
        "\n",
        "- Load the CIFAR 10 dataset, store values in `x_train`, `y_train`, `x_test`, `y_test`, respectively. \n",
        "- Randomly sample a subset of `x_train` and `x_test` to match the following shape.\n",
        "  - x_train.shape = (15000, 32, 32, 3) \n",
        "  - x_test.shape = (1000, 32, 32, 3) \n",
        "  - Reference ([link](https://docs.python.org/3/library/random.html#random.sample))\n"
      ],
      "metadata": {
        "id": "bl4kHQltCu1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's normalize `x_train` and `x_test` and set input shape using the following code.  \n",
        "\n",
        "                    x_train = x_train.astype('float32')/ 255.\n",
        "                    x_test = x_test.astype('float32')/ 255.\n",
        "\n",
        "                    input_shape = (x_train.shape[1], x_train.shape[2], 3)"
      ],
      "metadata": {
        "id": "-tGzIKOaEaa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Exercise 1-2\n",
        "\n",
        "- Fill in the line with your code below using `numpy.random.normal` to sample a gaussian noise of `mean` and `std` specified\n",
        "- Make sure the size of the noise is the same as the size of `input_data`  \n",
        "- Reference ([link](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html))\n",
        "\n",
        "                    def add_noise(input_data):\n",
        "                      mean , std = 0.0, 0.15 \n",
        "                      noise = ################# YOUR CODE HERE ##################\n",
        "                      noisy_data = np.clip(input_data + noise, 0., 1.) \n",
        "                      return noisy_data"
      ],
      "metadata": {
        "id": "MRoTZS2kXJqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, call the function you just wrote and plot noisy and clean images side by side. \n",
        "\n",
        "                    noisy_x_train = add_noise(x_train)\n",
        "                    noisy_x_test = add_noise(x_test)\n",
        "\n",
        "                    fig, ax = plt.subplots(4,4,figsize = (12,12), dpi = 80)\n",
        "                    for i, ax in enumerate(fig.axes):\n",
        "                      if i%2 ==0 :  \n",
        "                        ax.imshow(np.squeeze(x_train[i]))\n",
        "                        ax.set_title(f\"Clean\")\n",
        "                      else: \n",
        "                        ax.imshow(np.squeeze(noisy_x_train[i-1]))\n",
        "                        ax.set_title(\"Noisy\")\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153232811-6167c633-171c-4093-b31e-c2ec78a39338.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 1: exampe of clean and noisy images.</em>\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "RP-twjDCFbQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture of an autoencoder consists of two parts, the encoder and the decoder. We will be coding both parts in a single model called `autoencoder`.\n",
        "\n",
        "\n",
        "## Exercise 1-3\n",
        "\n",
        "- Initialize a Sequential model with following code \n",
        "\n",
        "                  autoencoder = Sequential()\n",
        "\n",
        "- Use `model.add()` function to build an autoencoder with the following architecture. Use `padding='same'` for all layers.\n",
        "\n",
        "  - 1st layer: convolutional layer with `28` filters, kernel size `3` by `3`, activation function ReLU\n",
        "  - 2nd layer: pooling layer with max pooling and pooling size `2` by `2`\n",
        "  - 3rd layer: convolutional layer with `28` filters, kernel size `3` by `3`, activation function ReLU\n",
        "  - 4th layer: pooling layer with max pooling and pooling size `2` by `2`.\n",
        "  This completes the encoder part\n",
        "  - 5th layer: inverse convolution (Conv2DTranspose) layer with `28` filters, kernel size `3` by `3`, stride of `2` and activation function ReLU\n",
        "  - 6th layer: inverse convolution (Conv2DTranspose) layer with `28` filters, kernel size `3` by `3`, stride of `2` and activation function ReLU\n",
        "  - 7th layer: convolutional layer with `3` filters, kernel size `3` by `3`, activation function sigmoid\n",
        "\n",
        "- Use `autoencoder.summary()` to check the built CNN encoder.\n",
        "\n",
        "- References \n",
        "  - Conv2D ([link](https://keras.io/api/layers/convolution_layers/convolution2d/)) \n",
        "  - MaxPool ([link](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
        "  - Conv2DTranspose ([link](https://keras.io/api/layers/convolution_layers/convolution2d_transpose/))\n"
      ],
      "metadata": {
        "id": "dhiJnxPS8Z0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compile and train the autoencoder. \n",
        "\n",
        "                    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "                    autoencoder.fit(noisy_x_train, x_train,\n",
        "                                    epochs = 20,\n",
        "                                    batch_size = 256, \n",
        "                                    shuffle = True,\n",
        "                                    verbose =2)\n",
        "\n",
        "Notice that the input data for training is `x_train`, `x_train`. Why is this the case? \n",
        "\n",
        "PS. Expect a training time about 11 minutes. "
      ],
      "metadata": {
        "id": "C9k9-dsIGvrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the model for future use. \n",
        "\n",
        "                    autoencoder.save(\"my_denoiser\")\n",
        "\n",
        "Load the saved model and plot noise/denoised `test` images.  \n",
        "\n",
        "                    loaded_model = keras.models.load_model(\"my_denoiser\")\n",
        "                    denoised_x_test= loaded_model.predict(x_test)\n",
        "\n",
        "                    fig, ax = plt.subplots(6,3,figsize = (8,19), dpi = 80)\n",
        "                    for i, ax in enumerate(fig.axes):\n",
        "                      if i%3 ==0 :  \n",
        "                        ax.imshow(np.squeeze(x_test[i]))\n",
        "                        ax.set_title(f\"Clean\")\n",
        "                      elif i%3==1:\n",
        "                        ax.imshow(np.squeeze(noisy_x_test[i-1]))\n",
        "                        ax.set_title(\"Noisy\")\n",
        "                      else: \n",
        "                        ax.imshow(np.squeeze(denoised_x_test[i-2]))\n",
        "                        ax.set_title(\"AE Denoised\")\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/154810843-58481cea-10b9-4f20-bc71-f78332d16e14.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 2: Clean, Noisy and Denoised images</em>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "_RFrXOmAHnr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise 2. Variational Autoencoder (VAE)\n",
        "\n",
        "Instead of directly learning the latent features from input samples, a VAE learns the distribution of latent features. This gives us the ability to generate new images from a learned distribution. We will be reducing the images from the MNIST dataset to a vector of just two dimensions (x, y). Then, we can take a random vector, for eample (2.5, 0.5), to generate an image.   \n",
        "\n",
        "\n",
        "## Exercise 2-1\n",
        "- load `mnist` data to `x_train`, `x_test`, `y_train`, `y_test`\n",
        "- reshape `x_train` (`x_train.shape[0]`, `28`, `28`, `1`) \n",
        "- change type of x_train to `float32` and normalize pixel values to `[0, 1]`"
      ],
      "metadata": {
        "id": "r4T_LrD38Lox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Unlike autoencoder, in VAE, we will create disjoint Encoder, Decoder, and Sampling layers. The three components will be stitched together later.  \n",
        "\n",
        "- Use the following code to set input shape, set latent dimensions, and implement a custom sampling layer. \n",
        "\n",
        "                input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
        "                latent_dims = 2\n",
        "\n",
        "                class Sampling(keras.layers.Layer):\n",
        "                  def call(self, distribution):\n",
        "                    mean, log_variance = distribution \n",
        "                    sample = tf.keras.backend.random_normal(shape = (tf.shape(mean)[0], tf.shape(mean)[1] ) )\n",
        "                    return mean + tf.exp(0.5*log_variance)*sample  # mean + std"
      ],
      "metadata": {
        "id": "6GAOPeIHMK7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code to build an encoder. \n",
        "\n",
        "                    encoder_input = Input(shape = input_shape)\n",
        "\n",
        "                    x = Conv2D(32, (3, 3), activation = \"relu\", strides=2)(encoder_input)\n",
        "                    x = Conv2D(64, (3, 3), activation = \"relu\", strides = 2)(x)\n",
        "                    x = Flatten()(x)\n",
        "                    x = Dense(16, activation = \"relu\")(x)\n",
        "\n",
        "                    mean = Dense(latent_dims)(x)\n",
        "                    variance = Dense(latent_dims)(x)\n",
        "                    encoded_input = Sampling()([mean, variance])\n",
        "\n",
        "                    encoder = Model(encoder_input, [mean, variance, encoded_input], name = \"encoder\")\n",
        "                    encoder.summary()"
      ],
      "metadata": {
        "id": "o9JdidD1MKM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code to build a decoder.  \n",
        "\n",
        "                    decoder_input = keras.Input(shape = (latent_dims,))\n",
        "\n",
        "                    x = Dense(7*7*64, activation = \"relu\")(decoder_input)\n",
        "                    x =  Reshape((7,7,64))(x)\n",
        "                    x = Conv2DTranspose(64, (3,3), activation = \"relu\", strides = 2, padding=\"same\")(x)\n",
        "                    x = Conv2DTranspose(32, (3,3), activation = \"relu\", strides = 2, padding = \"same\")(x)\n",
        "                    reconstructed_img = Conv2DTranspose(1, (3,3),  activation = \"sigmoid\", padding = \"same\")(x)\n",
        "\n",
        "                    decoder = keras.Model(decoder_input, reconstructed_img, name = \"decoder\")\n",
        "                    decoder.summary()"
      ],
      "metadata": {
        "id": "SfcaYsz0ML1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function of VAE combines the reconstruction loss as well as the KL-Divergence term. In the following, we will import some the loss function and stitch the encoder and decoder together."
      ],
      "metadata": {
        "id": "O2f5zkeMZtz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Exercise 2-2\n",
        "\n",
        "Fill in the function below with your code to do the following: \n",
        "- compile `vae` with `adam` optimizer \n",
        "- fit `vae` to `x_train` (NOT `x_train`, `x_train`) for `30` epochs\n",
        "- use batch size of `128` and set shuffle to `True` \n",
        "\n",
        "                    def training(vae, train_now):\n",
        "\n",
        "                      if train_now:\n",
        "                        ############ YOUR CODE HERE (1) ############\n",
        "                        ############ YOUR CODE HERE (2) ############\n",
        "\n",
        "                        vae.decoder.save(\"my_decoder\")\n",
        "                        trained_vae_decoder = tf.keras.models.load_model(\"my_decoder\")\n",
        "                      else: \n",
        "                        # Get the hosted trained model\n",
        "                        !wget -o -q https://github.com/poudel-bibek/Intro-to-AI-Assignments/files/8102846/my_trained_vae_decoder.zip\n",
        "                        !unzip -o -q ./my_trained_vae_decoder.zip -d unzipped/ \n",
        "                        trained_vae_decoder = tf.keras.models.load_model('./unzipped/my_trained_vae_decoder')\n",
        "\n",
        "                      return trained_vae_decoder\n",
        "\n",
        "- Reference: Compile and fit ([link](https://keras.io/api/models/model_training_apis/))\n"
      ],
      "metadata": {
        "id": "6PFMkGEE9e6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's execute the cell below."
      ],
      "metadata": {
        "id": "Q14Xssm5aaBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the expected training time of this model will take around 35 minutes. During the in-class activity, when the training starts, you can terminate the cell above and run the cell below."
      ],
      "metadata": {
        "id": "P9YZTcrcCdl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code, i.e., decoder of trained VAE, to sample data from the learned distribution and plot the results.\n",
        "\n",
        "                    fig, ax = plt.subplots(4,4,figsize = (12,13), dpi = 80)\n",
        "                    for i, ax in enumerate(fig.axes):\n",
        "                      random_latent_vector = np.random.rand(latent_dims)\n",
        "                      fake_image = trained_vae_decoder.predict(random_latent_vector.reshape(1,-1))[0]\n",
        "                      ax.imshow(fake_image.reshape(28, 28), cmap= 'gray') \n",
        "                      ax.set_title(f\"vector = {round(random_latent_vector[0],2), round(random_latent_vector[1],2)}\")\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153247392-0b43da98-66fa-474d-86c9-3797b4e7d332.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 3: Sample images from a learned distribution using random latent vectors (the vectors and sampled numbers may vary in your case).</em>\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "y7RC-OQBGaT9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V57qt6Dgw1w-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}